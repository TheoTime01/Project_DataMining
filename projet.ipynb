{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projet DataMining\n",
    "\n",
    "## Description du projet\n",
    "L'objectif de ce projet est de recommander des images de pokémons en fonction des préférences de l'utilisateur. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation librairies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "bat"
    }
   },
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation des bases de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import kaggle\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Télécharger le fichier de données\n",
    "kaggle.api.authenticate()\n",
    "kaggle.api.dataset_download_files('kvpratama/pokemon-images-dataset', path='.', unzip=True, quiet=False, force=False)\n",
    "kaggle.api.dataset_download_files('abcsds/pokemon', path='./data_csv', unzip=True, quiet=False, force=False)\n",
    "kaggle.api.dataset_download_files('avi1023/color-names', path='./data_csv', unzip=True, quiet=False, force=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# supprimer le dossier pokemon dans pokemon_img\n",
    "shutil.rmtree('./pokemon')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creation de la base de données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. Création de la base de données de pokémons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "import json\n",
    "from datetime import datetime\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_dir = r\"./pokemon_jpg/pokemon_jpg\" # chemin vers le répertoire contenant les images\n",
    "\n",
    "# initialise un dictionnaire pour stocker les métadonnées de toutes les images\n",
    "all_metadata = {}\n",
    "color_data={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# boucle à travers tous les fichiers d'image dans le répertoire\n",
    "for img_filename in os.listdir(img_dir):\n",
    "    if img_filename.endswith(\".jpg\") or img_filename.endswith(\".png\"):\n",
    "        # construire le chemin complet vers le fichier d'image\n",
    "        img_path = os.path.join(img_dir, img_filename)\n",
    "\n",
    "        # ouvrir le fichier d'image\n",
    "        with Image.open(img_path) as img:\n",
    "\n",
    "            # supprimer les images avec un nom qui ne sont pas de ce format: 1.jpg, 2.jpg, 3.jpg, etc.\n",
    "            if not img_filename.split(\".\")[0].isdigit():\n",
    "                continue\n",
    "\n",
    "            # extraire les métadonnées de l'image\n",
    "            img_filename= img.filename\n",
    "            img_format = img.format\n",
    "            img_size = img.size\n",
    "            img_orientation = \"landscape\" if img_size[0] > img_size[1] else \"portrait\"\n",
    "            creation_date =  datetime.fromtimestamp(os.path.getctime(img_path)).strftime('%d/%m/%Y')\n",
    "\n",
    "            # créer un dictionnaire de métadonnées pour cette image\n",
    "            metadata = {\n",
    "                #on veut juste le nom de l'image\n",
    "                \"id\": int((img_filename.split(\"\\\\\")[-1]).split(\".\")[0]),\n",
    "                \"format\": img_format,\n",
    "                \"size\": img_size,\n",
    "                \"orientation\": img_orientation,\n",
    "                \"creation_date\": creation_date,\n",
    "                \"tags\": \"\"\n",
    "            }\n",
    "\n",
    "            # ajouter les métadonnées de cette image au dictionnaire de toutes les métadonnées\n",
    "            all_metadata[img_filename.split(\"\\\\\")[-1]] = metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajouter les métadonnées au fichier JSON\n",
    "with open('database.json', \"w\") as f:\n",
    "    json.dump(all_metadata, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Création de la base de données de couleurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# charger le fichier csv\n",
    "df = pd.read_csv(\"./data_csv/color_names.csv\", sep=',', header=0)\n",
    "\n",
    "# sélectionner les colonnes Name et Hex (24 bit)\n",
    "df_selected = df.loc[:, [\"Name\", \"Hex (24 bit)\"]]\n",
    "df_selected.rename(columns={\"Hex (24 bit)\": \"Hex\"}, inplace=True)\n",
    "\n",
    "# remplacer # par rien\n",
    "df_selected['Hex'] = df_selected['Hex'].str.replace('#', '')\n",
    "\n",
    "with open('color_names.json', 'w') as f:\n",
    "    f.write(df_selected.to_json(orient='records')) \n",
    "\n",
    "with open('color_names.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "with open('color_names.json', 'w') as f:\n",
    "    json.dump(data, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III. Ajout des couleurs aux pokémons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from sklearn.cluster import MiniBatchKMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# boucle à travers tous les fichiers d'image dans le répertoire\n",
    "color_data = {}\n",
    "img_dir = r\"./pokemon_jpg/pokemon_jpg\" \n",
    "for img_filename in os.listdir(img_dir): \n",
    "    if img_filename.endswith(\".jpg\") or img_filename.endswith(\".png\"):\n",
    "        # Construire le chemin complet vers le fichier d'image\n",
    "        img_path = os.path.join(img_dir, img_filename)\n",
    "        # Ouvrir l'image\n",
    "        with Image.open(img_path) as img:\n",
    "            \n",
    "            \n",
    "            # Supprimer les images avec un nom qui ne sont pas de ce format: 1.jpg, 2.jpg, 3.jpg, etc.\n",
    "            if not img_filename.split(\".\")[0].isdigit():\n",
    "                continue\n",
    "\n",
    "            pixel_matrix = np.array(img) # Convertir l'image en matrice de pixels\n",
    "\n",
    "            # Extraire les valeurs R, G, B\n",
    "            pixel_data = pixel_matrix.reshape((-1, 3))\n",
    "\n",
    "            # Utiliser MiniBatchKMeans pour trouver le cluster le plus grand\n",
    "            kmeans = MiniBatchKMeans(n_clusters=2, random_state=0).fit(pixel_data)\n",
    "            main_color = kmeans.cluster_centers_[np.argmax(np.unique(kmeans.labels_, return_counts=True)[1])]\n",
    "            hex_value = \"{0:02X}{1:02X}{2:02X}\".format(int(main_color[0]), int(main_color[1]), int(main_color[2]))\n",
    "\n",
    "\n",
    "            # créer un dictionnaire de couleur pour cette image\n",
    "            color = {\n",
    "                \"id\": int((img_filename.split(\"\\\\\")[-1]).split(\".\")[0]),\n",
    "                \"couleur dominante\": main_color.tolist(),\n",
    "                \"nom couleur\": hex_value\n",
    "            }\n",
    "\n",
    "            # ajouter les couleurs de cette image au dictionnaire de toutes les couleurs\n",
    "            color_data[(img_filename.split(\"\\\\\")[-1]).split(\".\")[0]] = color\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajouter les couleurs au fichier JSON\n",
    "with open('color_data.json', 'w') as f:\n",
    "    json.dump(color_data, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare les couleurs de l'image avec la liste des couleurs du fichier json\n",
    "\n",
    "with open('color_names.json', 'r') as f:\n",
    "    color_names = json.load(f)\n",
    "\n",
    "with open('color_data.json', 'r') as f:\n",
    "    color_data = json.load(f)\n",
    "\n",
    "for pokemon in color_data:\n",
    "    color_hex = color_data[pokemon]['nom couleur']\n",
    "    for color in color_names:\n",
    "        color_rgb = (int(color_hex[1:2], 16), int(color_hex[2:4], 16), int(color_hex[4:], 16))\n",
    "        color_rgb_names = (int(color['Hex'][1:2], 16), int(color['Hex'][2:4], 16), int(color['Hex'][4:], 16))\n",
    "        # verifie si les trois valeurs sont les memes\n",
    "        if (color_rgb[0] == color_rgb_names[0] and color_rgb[1] == color_rgb_names[1] and color_rgb[2] == color_rgb_names[2]):\n",
    "            color_data[pokemon]['nom couleur'] = color['Name']\n",
    "        # verifie si deux des trois valeurs sont les memes\n",
    "        elif ((color_rgb[0] == color_rgb_names[0] and color_rgb[1] == color_rgb_names[1])\n",
    "        or (color_rgb[0] == color_rgb_names[0] and color_rgb[2] == color_rgb_names[2]) \n",
    "        or (color_rgb[1] == color_rgb_names[1] and color_rgb[2] == color_rgb_names[2])):\n",
    "            color_data[pokemon]['nom couleur'] = color['Name']\n",
    "        # verifie si une des trois valeurs est la meme\n",
    "        elif (color_rgb[0] == color_rgb_names[0] or color_rgb[1] == color_rgb_names[1] or color_rgb[2] == color_rgb_names[2]):\n",
    "            color_data[pokemon]['nom couleur'] = color['Name']\n",
    "\n",
    "with open('color_data.json', 'w') as f:\n",
    "    json.dump(color_data, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ajoute les couleurs au fichier json principal\n",
    "with open('database.json', 'r') as f:\n",
    "    pokemon_data = json.load(f)\n",
    "\n",
    "with open('color_data.json', 'r') as f:\n",
    "    color_data = json.load(f)\n",
    "\n",
    "# si l'id du pokemon est le meme que l'id de la couleur, ajoute la couleur au pokemon\n",
    "for pokemon in pokemon_data:\n",
    "    for color in color_data:\n",
    "        if pokemon_data[pokemon]['id'] == color_data[color]['id']:\n",
    "            pokemon_data[pokemon]['couleur dominante'] = color_data[color]['nom couleur']\n",
    "\n",
    "with open('database.json', 'w') as f:\n",
    "    json.dump(pokemon_data, f, indent=4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ajout de tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger les données de tags.json dans data_d[\"tags\"]\n",
    "df = pd.read_csv(r\"./data_csv/Pokemon.csv\", sep=',', header=0)\n",
    "df_selected = df.loc[:, ['#','Name', 'Type 1', 'Type 2', 'Generation', 'Legendary']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renommer la colonne # en id\n",
    "df_selected.rename(columns={'#': 'id'}, inplace=True)\n",
    "\n",
    "with open('tags.json', 'w') as f:\n",
    "    f.write(df_selected.to_json(orient='records')) \n",
    "\n",
    "with open('tags.json', 'r') as f:\n",
    "    data_t = json.load(f)\n",
    "\n",
    "with open('tags.json', 'w') as f:\n",
    "    json.dump(data_t, f, indent=4)\n",
    "\n",
    "with open('database.json', 'r') as f:\n",
    "    data_d = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger les données de tags.json dans data_d[\"tags\"]\n",
    "for key in data_d:\n",
    "    for i in range(len(data_t)):\n",
    "        if data_d[key][\"id\"] == data_t[i][\"id\"]:\n",
    "            data_d[key][\"tags\"] = data_t[i]\n",
    "\n",
    "#Enlever l'id de data_d[\"tags\"]\n",
    "for key in data_d:\n",
    "    data_d[key][\"tags\"].pop(\"id\")\n",
    "\n",
    "# Enregistrer les données dans database.json\n",
    "with open('database.json', 'w') as f:\n",
    "    json.dump(data_d, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creation des utilisateurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from random import randint, choice\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction pour charger les caractéristiques d'une image\n",
    "def load(filename):\n",
    "    train={}\n",
    "    test={}\n",
    "    with open(filename, \"r\") as f:\n",
    "        data=json.load(f)\n",
    "    for i in data:\n",
    "        if data[i][\"id\"]<598:\n",
    "            train[i]=data[i] #85% des données\n",
    "        else:\n",
    "            test[i]=data[i] #15% des données\n",
    "    return train,test\n",
    "\n",
    "# Fonction de filtrage en fonction des préférences utilisateur\n",
    "def filter_images(images, color, legendary):\n",
    "    filtered_images = []\n",
    "    for image in images.values():\n",
    "        couleur = image[\"couleur dominante\"]\n",
    "        legendaire = image[\"tags\"][\"Legendary\"]\n",
    "        tags= image[\"tags\"]\n",
    "        tags[\"color\"]=color # ajouter color dans tags\n",
    "        # ajouter la lettre du debut du nom du pokemon dans tags\n",
    "        tags[\"first_letter\"]=tags[\"Name\"][0]\n",
    "        if couleur == color and not(legendaire^legendary):\n",
    "            filtered_images.append(tags)\n",
    "    return filtered_images\n",
    "\n",
    "# Fonction de génération des préférences utilisateur\n",
    "def get_user_preferences(images,color_t):\n",
    "    legendary_t=[True,False]\n",
    "    color = color_t[randint(0, len(color_t)-1)]\n",
    "    legendary = legendary_t[randint(0, len(legendary_t)-1)]\n",
    "    filtered_images = filter_images(images, color, legendary)\n",
    "    return filtered_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# récuperation des nom couleurs dans database.json\n",
    "with open(\"database.json\", \"r\") as f:\n",
    "    data=json.load(f)\n",
    "\n",
    "color_t=[]\n",
    "for i in data:\n",
    "    if data[i][\"couleur dominante\"] not in color_t:\n",
    "        color_t.append(data[i][\"couleur dominante\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#simulation de l'utilisateur\n",
    "img,test=load(\"database.json\")\n",
    "\n",
    "favorite_t=[\"favorite\",\"notfavorite\"]\n",
    "all_user={}\n",
    "\n",
    "for i in range(100):#100 utilisateurs\n",
    "    result=[]\n",
    "    data=get_user_preferences(img,color_t)\n",
    "    if len(data)==0:\n",
    "        continue\n",
    "\n",
    "    for k in range(len(data)):\n",
    "        result.append(favorite_t[randint(0, len(favorite_t)-1)])\n",
    "    all_user[i]={'data':data,'result':result}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sauvegarde des données\n",
    "with open(\"user.json\", \"w\") as f:\n",
    "    json.dump(all_user, f, indent=4)\n",
    "\n",
    "#sauvegarder les données de test dans un fichier json\n",
    "with open(\"test.json\", \"w\") as f:\n",
    "    json.dump(test, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrainement du modèle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A. Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import graphviz\n",
    "import pydotplus\n",
    "from IPython.display import Image, display\n",
    "import json\n",
    "import pickle\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importer les données de l'utilisateur\n",
    "with open('user.json', \"r\") as f:\n",
    "        user=json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creation du tree\n",
    "dtc = tree.DecisionTreeClassifier()\n",
    "\n",
    "#creation des labels encoder\n",
    "le1 = LabelEncoder()\n",
    "le2 = LabelEncoder()\n",
    "le3 = LabelEncoder()\n",
    "le4 = LabelEncoder()\n",
    "le5 = LabelEncoder()\n",
    "le6 = LabelEncoder()\n",
    "le7 = LabelEncoder()\n",
    "le8 = LabelEncoder()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __A.1 Création du modèle__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating dataframes\n",
    "for i in user:\n",
    "    data = user[str(i)][\"data\"]\n",
    "    result = user[str(i)][\"result\"]\n",
    "    dataframe = pd.DataFrame(data, columns=[\"Name\",\"Type 1\", \"Type 2\", \"Generation\",\"legendary\", \"color\",\"first_letter\"])\n",
    "    resultframe = pd.DataFrame(result, columns=[\"favorite\"])\n",
    "\n",
    "    # generating numerical labels\n",
    "    dataframe[\"Name\"] = le1.fit_transform(dataframe[\"Name\"])\n",
    "    dataframe[\"Type 1\"] = le2.fit_transform(dataframe[\"Type 1\"])\n",
    "    dataframe[\"Type 2\"] = le3.fit_transform(dataframe[\"Type 2\"])\n",
    "    dataframe[\"Generation\"] = le4.fit_transform(dataframe[\"Generation\"])\n",
    "    dataframe[\"legendary\"] = le5.fit_transform(dataframe[\"legendary\"])\n",
    "    dataframe[\"color\"] = le6.fit_transform(dataframe[\"color\"])\n",
    "    dataframe[\"first_letter\"] = le7.fit_transform(dataframe[\"first_letter\"])\n",
    "    resultframe[\"favorite\"] = le8.fit_transform(resultframe[\"favorite\"])\n",
    "    # Use of decision tree classifiers\n",
    "    dtc = dtc.fit(dataframe.values, resultframe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __A.2 Visualisation du modèle__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dot_data = tree.export_graphviz(\n",
    "    dtc,\n",
    "    out_file=None,\n",
    "    feature_names=dataframe.columns,\n",
    "    filled=True,\n",
    "    rounded=True,\n",
    "    class_names=le8.inverse_transform(resultframe.favorite.unique()),\n",
    "    special_characters=True,\n",
    ")\n",
    "graph = graphviz.Source(dot_data)\n",
    "\n",
    "pydot_graph = pydotplus.graph_from_dot_data(dot_data)\n",
    "img = Image(pydot_graph.create_png())\n",
    "display(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __A.3 Evaluation du modèle__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy:\",metrics.accuracy_score(resultframe, dtc.predict(dataframe)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating predictions\n",
    "y_pred = dtc.predict(dataframe)\n",
    "\n",
    "# creating confusion matrix\n",
    "cm = confusion_matrix(resultframe, y_pred, normalize='true')\n",
    "    \n",
    "# displaying confusion matrix\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['not favorite', 'favorite'])\n",
    "disp.plot(cmap='Blues')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B. Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __B.1 Creation du modèle__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.utils import plot_model\n",
    "import json\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load user input data\n",
    "with open('user.json', 'r') as f:\n",
    "    user_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create label encoders\n",
    "le1 = LabelEncoder()\n",
    "le2 = LabelEncoder()\n",
    "le3 = LabelEncoder()\n",
    "le4 = LabelEncoder()\n",
    "le5 = LabelEncoder()\n",
    "le6 = LabelEncoder()\n",
    "le7 = LabelEncoder()\n",
    "le8 = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframes\n",
    "for i in user_data:\n",
    "    data = user_data[str(i)][\"data\"]\n",
    "    result = user_data[str(i)][\"result\"]\n",
    "    dataframe = pd.DataFrame(data, columns=[\"Name\",\"Type 1\", \"Type 2\", \"Generation\",\"legendary\", \"color\",\"first_letter\"])\n",
    "    resultframe = pd.DataFrame(result, columns=[\"favorite\"])\n",
    "\n",
    "    # Generate numerical labels\n",
    "    dataframe[\"Name\"] = le1.fit_transform(dataframe[\"Name\"])\n",
    "    dataframe[\"Type 1\"] = le2.fit_transform(dataframe[\"Type 1\"])\n",
    "    dataframe[\"Type 2\"] = le3.fit_transform(dataframe[\"Type 2\"])\n",
    "    dataframe[\"Generation\"] = le4.fit_transform(dataframe[\"Generation\"])\n",
    "    dataframe[\"legendary\"] = le5.fit_transform(dataframe[\"legendary\"])\n",
    "    dataframe[\"color\"] = le6.fit_transform(dataframe[\"color\"])\n",
    "    dataframe[\"first_letter\"] = le7.fit_transform(dataframe[\"first_letter\"])\n",
    "    resultframe[\"favorite\"] = le8.fit_transform(resultframe[\"favorite\"])\n",
    "\n",
    "    # Split data into training and testing sets\n",
    "    train_dataset = dataframe.sample(frac=0.8, random_state=0)\n",
    "    test_dataset = dataframe.drop(train_dataset.index)\n",
    "\n",
    "    # Split labels into training and testing sets\n",
    "    train_labels = resultframe.sample(frac=0.8, random_state=0)\n",
    "    test_labels = resultframe.drop(train_labels.index)\n",
    "\n",
    "    # Define the model\n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Dense(32, activation='relu', input_shape=(7,)),\n",
    "        tf.keras.layers.Dense(16, activation='relu'),\n",
    "        tf.keras.layers.Dense(8, activation='relu'),\n",
    "        tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # Train the model\n",
    "    history = model.fit(train_dataset, train_labels, validation_data=(test_dataset, test_labels), epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __B.2 Visualisation du modèle__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# affichage du modele de reseau de neurone\n",
    "plot_model(model, to_file='model.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __B.3 Evaluation du modèle__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model\n",
    "test_loss, test_acc = model.evaluate(train_dataset, train_labels)\n",
    "print('Test accuracy:', test_acc)\n",
    "print('Test loss:', test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# afficher la matrice de confusion pour un reseau de neurone\n",
    "y_pred = model.predict_classes(train_dataset)\n",
    "cm = confusion_matrix(train_labels, y_pred, normalize='true')\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['not favorite', 'favorite'])\n",
    "disp.plot(cmap='Blues')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C. Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __C.1 Creation du modèle__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import json\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.tree import plot_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load user input data\n",
    "with open('user.json', 'r') as f:\n",
    "    user_data = json.load(f)\n",
    "\n",
    "# Create label encoders\n",
    "le1 = LabelEncoder()\n",
    "le2 = LabelEncoder()\n",
    "le3 = LabelEncoder()\n",
    "le4 = LabelEncoder()\n",
    "le5 = LabelEncoder()\n",
    "le6 = LabelEncoder()\n",
    "le7 = LabelEncoder()\n",
    "le8 = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframes\n",
    "for i in user_data:\n",
    "    data = user_data[str(i)][\"data\"]\n",
    "    result = user_data[str(i)][\"result\"]\n",
    "    dataframe = pd.DataFrame(data, columns=[\"Name\",\"Type 1\", \"Type 2\", \"Generation\",\"legendary\", \"color\",\"first_letter\"])\n",
    "    resultframe = pd.DataFrame(result, columns=[\"favorite\"])\n",
    "\n",
    "    # Generate numerical labels\n",
    "    dataframe[\"Name\"] = le1.fit_transform(dataframe[\"Name\"])\n",
    "    dataframe[\"Type 1\"] = le2.fit_transform(dataframe[\"Type 1\"])\n",
    "    dataframe[\"Type 2\"] = le3.fit_transform(dataframe[\"Type 2\"])\n",
    "    dataframe[\"Generation\"] = le4.fit_transform(dataframe[\"Generation\"])\n",
    "    dataframe[\"legendary\"] = le5.fit_transform(dataframe[\"legendary\"])\n",
    "    dataframe[\"color\"] = le6.fit_transform(dataframe[\"color\"])\n",
    "    dataframe[\"first_letter\"] = le7.fit_transform(dataframe[\"first_letter\"])\n",
    "    resultframe[\"favorite\"] = le8.fit_transform(resultframe[\"favorite\"])\n",
    "\n",
    "    # Split data into training and testing sets\n",
    "    train_data = dataframe.sample(frac=0.8, random_state=0)\n",
    "    test_data = dataframe.drop(train_data.index)\n",
    "\n",
    "    # Split labels into training and testing sets\n",
    "    train_labels = resultframe.sample(frac=0.8, random_state=0)\n",
    "    test_labels = resultframe.drop(train_labels.index)\n",
    "\n",
    "    # Define the model\n",
    "    model = RandomForestClassifier(n_estimators=100, random_state=0)\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(train_data, train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __C.2 Visualisation du modèle__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_tree(model.estimators_[0], filled=True, rounded=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __C.3 Evaluation du modèle__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model\n",
    "y_pred = model.predict(train_data)\n",
    "print(\"Accuracy:\", accuracy_score(train_labels, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# afficher la matrice de confusion\n",
    "cm = confusion_matrix(train_labels, y_pred, normalize='true')\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['not favorite', 'favorite'])\n",
    "disp.plot(cmap='Blues')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Syteme de recommandation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualisation des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5e709a68c8bffd8ca64ede960b472aee5cbbab0a7eefe704a97155fcd513aef5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
